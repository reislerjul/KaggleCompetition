{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "import sklearn.linear_model as model\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Michelle's method for importing data since I can't do it correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX =  (20000, 1000)\n",
      "trainY =  (20000,)\n",
      "testX =  (10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.genfromtxt('Data/training_data.txt',dtype='str')\n",
    "test_data = np.genfromtxt('Data/test_data.txt',dtype='str')\n",
    "#train_data = np.loadtxt('training_data.txt',  delimiter=' ')\n",
    "#test_data = np.loadtxt('test_data.txt')\n",
    "train_labels = train_data[0, :]\n",
    "train_stars = train_data[1:, 0]\n",
    "train_reviews = train_data[1:, 1:]\n",
    "\n",
    "test_labels = test_data[0, :]\n",
    "#test_stars = train_data[1:, 0]\n",
    "test_reviews = test_data[1:, 0:]\n",
    "\n",
    "trainX = train_reviews\n",
    "trainY = train_stars\n",
    "testX = test_reviews\n",
    "#testY = test_stars\n",
    "\n",
    "print(\"trainX = \", trainX.shape)\n",
    "print(\"trainY = \", trainY.shape)\n",
    "print(\"testX = \", testX.shape)\n",
    "\n",
    "\n",
    "for i in range(0, len(trainX)):\n",
    "    for j in range(0, len(trainX[0])):\n",
    "        trainX[i][j] = int(trainX[i][j])\n",
    "\n",
    "for i in range(0, len(testX)):\n",
    "    for j in range(0, len(testX[0])):\n",
    "        testX[i][j] = int(testX[i][j])\n",
    "\n",
    "for i in range(0, len(trainY)):\n",
    "        trainY[i] = int(trainY[i])\n",
    "#for i in range(0, len(trainY)):\n",
    "        #testY[i] = int(testY[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for classification error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_error(y, y_pred):\n",
    "    misclassified = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] != y_pred[i]:\n",
    "            misclassified += 1\n",
    "    return float(misclassified) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into 80% training set and 20% test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_rows = []\n",
    "for i in range(len(trainY)):\n",
    "    num_rows.append(i)\n",
    "    \n",
    "np.random.shuffle(num_rows)\n",
    "train_indices = num_rows[:16000]\n",
    "valid_indices = num_rows[16000:]\n",
    "\n",
    "train_X = []\n",
    "train_y = []\n",
    "valid_X = []\n",
    "valid_y = []\n",
    "\n",
    "for index in train_indices:\n",
    "    train_X.append(trainX[index])\n",
    "    train_y.append(trainY[index])\n",
    "    \n",
    "for index in valid_indices:\n",
    "    valid_X.append(trainX[index])\n",
    "    valid_y.append(trainY[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Michelle's code, it doesn't actually convert the array contents into integers because she tried to do it in place. This code does it correctly out of place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X2 = []\n",
    "for row in train_X:\n",
    "    temp = []\n",
    "    for element in row:\n",
    "        temp.append(int(element))\n",
    "    train_X2.append(temp)\n",
    "\n",
    "valid_X2 = []\n",
    "for row in valid_X:\n",
    "    temp = []\n",
    "    for element in row:\n",
    "        temp.append(int(element))\n",
    "    valid_X2.append(temp)\n",
    "    \n",
    "valid_y2 = []\n",
    "for row in valid_y:\n",
    "    valid_y2.append(int(row))\n",
    "    \n",
    "train_y2 = []\n",
    "for row in train_y:\n",
    "    train_y2.append(int(row))\n",
    "    \n",
    "test_X2 = []\n",
    "for row in testX:\n",
    "    temp = []\n",
    "    for element in row:\n",
    "        temp.append(int(element))\n",
    "    test_X2.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert everything back to a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X2 = np.array(train_X2)\n",
    "valid_X2 = np.array(valid_X2)\n",
    "train_y2 = np.array(train_y2)\n",
    "valid_y2 = np.array(valid_y2)\n",
    "test_X2 = np.array(test_X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = model.LogisticRegression()\n",
    "logistic.fit(train_X2, train_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the classification error on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.122625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_error(logistic.predict(train_X2), train_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the classification error on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1525"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_error(logistic.predict(valid_X2), valid_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression works better than a random forest. Now, we want to combine the training and validation sets again so that we can train our model on all the data to prevent overfitting. We will then use this to predict on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_X = np.concatenate((train_X2, valid_X2))\n",
    "all_y = np.concatenate((train_y2, valid_y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = model.LogisticRegression()\n",
    "logistic.fit(all_X, all_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for writing to the text file for the submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeToText(predictions):\n",
    "    array = [[\"Id\",\"Prediction\"]]\n",
    "    index = 1\n",
    "    for i in range(len(predictions)):\n",
    "        predict = predictions[index - 1]\n",
    "        array.append([index, int(predictions[index - 1])])\n",
    "        index += 1\n",
    "    f = open(\"test_logistic_prediction_TFIDF.txt\", 'w')\n",
    "    writer = csv.writer(f, delimiter=',', quotechar='|')\n",
    "    writer.writerows(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writeToText(logistic.predict(test_X2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to convert the set into a TF-IDF matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TFIDF(X, labels):\n",
    "    documents = []\n",
    "\n",
    "    for element in X:\n",
    "        temp = ''\n",
    "        for i in range(len(element)):\n",
    "            word = labels[i + 1] + ' '\n",
    "            new_word = word * element[i]\n",
    "            temp += (new_word)\n",
    "        documents.append(temp)\n",
    "        \n",
    "    tokenize = lambda doc: doc.lower().split(\" \")\n",
    "    sklearn_tfidf = TfidfVectorizer(norm='l2',min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, tokenizer=tokenize)\n",
    "    return sklearn_tfidf.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model using the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = model.LogisticRegression()\n",
    "logistic.fit(TFIDF(train_X2, train_labels), train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14525"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_error(logistic.predict(TFIDF(valid_X2, train_labels)), valid_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has a lower classification error than the basic regression. We will now undergo the same procedure as in the last section to get the test predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = model.LogisticRegression()\n",
    "logistic.fit(TFIDF(all_X, train_labels), all_y)\n",
    "writeToText(logistic.predict(TFIDF(test_X2, train_labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
